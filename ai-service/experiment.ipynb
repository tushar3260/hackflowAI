{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# AI Scoring Experiment Notebook\n",
                "\n",
                "This notebook demonstrates the text analysis logic used in the Hackflow AI service. \n",
                "It uses TF-IDF and Cosine Similarity to score project submissions against ideal archetypes."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import numpy as np\n",
                "from sklearn.feature_extraction.text import TfidfVectorizer\n",
                "from sklearn.metrics.pairwise import cosine_similarity\n",
                "import nltk\n",
                "from nltk.sentiment import SentimentIntensityAnalyzer\n",
                "\n",
                "# Download NLTK data (lightweight)\n",
                "try:\n",
                "    nltk.data.find('vader_lexicon')\n",
                "except LookupError:\n",
                "    nltk.download('vader_lexicon')\n",
                "\n",
                "try:\n",
                "    nltk.data.find('punkt')\n",
                "except LookupError:\n",
                "    nltk.download('punkt')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# --- IDEAL PROJECT ARCHETYPES ---\n",
                "# We compare submissions against these \"perfect\" descriptions.\n",
                "\n",
                "IDEAL_INNOVATION = \"\"\"\n",
                "This project introduces a novel, groundbreaking approach to solving a complex problem. \n",
                "It utilizes state-of-the-art technology, unique algorithms, and patent-pending methods. \n",
                "The solution is a game-changer, disrupting the current market with creativity and out-of-the-box thinking.\n",
                "It leverages generative AI, blockchain, or quantum computing in a way never seen before.\n",
                "\"\"\"\n",
                "\n",
                "IDEAL_TECHNICAL = \"\"\"\n",
                "The system architecture is highly scalable, secure, and optimized for performance. \n",
                "It uses microservices, Docker, Kubernetes, and efficient database schemas. \n",
                "The code is clean, modular, and follows best practices with low latency and high throughput. \n",
                "API endpoints are RESTful or GraphQL, with robust authentication and encryption.\n",
                "Implementation details show a deep understanding of the tech stack (React, Node, Python, cloud).\n",
                "\"\"\"\n",
                "\n",
                "IDEAL_BUSINESS = \"\"\"\n",
                "The product has a clear target audience and a strong business model. \n",
                "It addresses a significant market need with a cost-effective solution. \n",
                "The plan includes user acquisition strategies, retention metrics, and a path the monetization.\n",
                "It demonstrates high ROI, financial feasibility, and real-world impact.\n",
                "\"\"\"\n",
                "\n",
                "# Combined corpus for vectorization training\n",
                "CORPUS = [IDEAL_INNOVATION, IDEAL_TECHNICAL, IDEAL_BUSINESS]\n",
                "\n",
                "# Initialize Vectorizer\n",
                "vectorizer = TfidfVectorizer(stop_words='english')\n",
                "# \"Train\" the vectorizer on our ideal archetypes\n",
                "tfidf_matrix_archetypes = vectorizer.fit_transform(CORPUS)\n",
                "\n",
                "# Initialize Sentiment Analyzer\n",
                "sia = SentimentIntensityAnalyzer()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def analyze_project(name, notes_text, extracted_text, github_url):\n",
                "    print(f\"--- Analyzing: {name} ---\")\n",
                "    combined_text = (notes_text or \"\") + \"\\n\" + (extracted_text or \"\")\n",
                "    \n",
                "    if not combined_text or len(combined_text.strip()) < 10:\n",
                "        print(\"Text too short to analyze.\")\n",
                "        return\n",
                "\n",
                "    # 1. Similarity Scoring\n",
                "    submission_vector = vectorizer.transform([combined_text])\n",
                "    similarities = cosine_similarity(submission_vector, tfidf_matrix_archetypes)\n",
                "    \n",
                "    inn_score = similarities[0][0]\n",
                "    tech_score = similarities[0][1]\n",
                "    biz_score = similarities[0][2]\n",
                "    \n",
                "    # 2. Sentiment Analysis\n",
                "    sentiment = sia.polarity_scores(combined_text)['compound']\n",
                "    \n",
                "    # 3. Lexical Diversity\n",
                "    words = nltk.word_tokenize(combined_text)\n",
                "    unique_words = set(words)\n",
                "    diversity = len(unique_words) / len(words) if words else 0\n",
                "\n",
                "    print(f\"Innovation Match: {inn_score:.4f}\")\n",
                "    print(f\"Technical Match: {tech_score:.4f}\")\n",
                "    print(f\"Business Match:   {biz_score:.4f}\")\n",
                "    print(f\"Sentiment Score:  {sentiment:.4f}\")\n",
                "    print(f\"Lexical Diversity: {diversity:.4f}\")\n",
                "    \n",
                "    return inn_score, tech_score, biz_score"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# TEST CASE 1: Strong Submission\n",
                "strong_notes = \"We built a decentralized application using Ethereum smart contracts and IPFS for storage. The system uses Zero-Knowledge Proofs for privacy. It solves the issue of data sovereignty.\"\n",
                "strong_tech = \"Technically, we used React for frontend, Node.js for backend, and Solidity for contracts. The architecture is microservices based with Docker containerization.\"\n",
                "\n",
                "analyze_project(\"Strong Submission\", strong_notes, strong_tech, \"http://github.com/repo\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# TEST CASE 2: Weak Submission\n",
                "weak_notes = \"We made a simple website.\"\n",
                "weak_tech = \"It has a login page.\"\n",
                "\n",
                "analyze_project(\"Weak Submission\", weak_notes, weak_tech, \"\")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.8.5"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}